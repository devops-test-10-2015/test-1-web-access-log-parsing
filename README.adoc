= Test 2 - Web Access Log Parsing

== Requirements

Consume web access log files and emit the following metrics:

* No. of successful requests per minute
* No. of error requests per minute
* Mean response time per minute
* MBs sent per minute

=== Data

Solution developed with this data : https://s3-eu-west-1.amazonaws.com/skyscanner-recruitement-resources/devops/access-log-example/c930ecf4b0a4426e619bddd8752c475ea772427db13eb92ee6a1a79b248ec0dc/access.log[access.log]

=== Log format

As http://httpd.apache.org/docs/2.2/mod/mod_log_config.html[Defined here] : "%a %l %u %t \"%r\" %>s %b %D"

Parse with https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns[Logstash] using `%{COMMONAPACHELOG} %{BASE10NUM:time_to_serve}`.

== Project Status

A report is being produced and there is testing but I think it could do with
some more verification.

Ideally I would like to have additional tasks to verify that that the overall
number from the original and the report match but it seems I am out of time.

Some additional Spock integration test would also be useful.

== How to run

=== Environment prerequisite

To produce the reports from the logs you need the following installed:

|===
|Technology | Version tested aginst

|Java
|openjdk version "1.8.0_60"

|Logstash
|1.5.4

|===


=== Create stats per minute report

The report is created using a couple of different tasks so these are pulled
together with Gradle. You do not need to have Gradle installed as it can be run
using the wrapper.

Running the parser against the JSON version of the log data will produce a
report to standard out with the metrics for each minute.

The report format is line delimited JSON.

To run the report on the provided data do this:

    ./gradlew createAccessLogReport

If you want to hide the Gradle messages and only see the report you can pass
the `-q` flag to `gradlew`.

The `jsonData` property can be supplied if you wish to override the value in
`gradle.properties` and run the report on test files.

    ./gradlew createAccessLogReport [-PapacheLog=test_data/20_200s_over_2_minutes.log]


=== Testing

There are a number of integration tests using Spock. These test small altered
samples of the original data produce the expected report output.

They can be run by:

    ./gradlew test

== Decisions

=== Technology

Going with Logstash for the parsing as parsing Apache logs is a standard task
for Logstash and is tried and tested.

I would like to have done the stats gathering in Elastic Search but I could not
make that work in the available time.


== Plan

* Get the sample logs
* Write the requirements
* Decide technology for solution
* Create Logstash conf to parse the logs
* Set up testing
* Get the numbers
* Add any missing documentation

=== Getting the numbers

To get the information from the data try these solutions in order:

* Logstash metrics plugin
** The default seems to be that this will give you rates based on when entries are added to the logs. I cannot find a way to use the timestamp in the log.
** I have found a way to set the Logstash timestamp to the timestamp value from the original log but the rates are per second.
** I looked through all the other filter plugins and could not find anything suitable.
* Elastic Search
** I tried this using aggregation but I could not work out how to get the values a per minute.
** I am going to give up and go with the scripting option.
* take the json output from logstash and do write a script

=== Testing

Take a small part of the log and manually count the up the values and use that
for testing.

== Issues

=== Manual verification

I have done a crude manual verification and the number of minutes seem to match
but this check could be automated.

    ± cut -f2 -d'[' access.log | cut -f1 -d']' | sed 's/:[0-9][0-9] /:XX /' | sort -u | grep -v "+0200" | wc -l
    308

    ± wc -l out.json
    308 out.json

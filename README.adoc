= Test 2 - Web Access Log Parsing


== Requirements

Consume web access log files and emit the following metrics:

* No. of successful requests per minute
* No. of error requests per minute
* Mean response time per minute
* MBs sent per minute

=== Data

Solution developed with this data : https://s3-eu-west-1.amazonaws.com/skyscanner-recruitement-resources/devops/access-log-example/c930ecf4b0a4426e619bddd8752c475ea772427db13eb92ee6a1a79b248ec0dc/access.log[access.log]

=== Log format

As http://httpd.apache.org/docs/2.2/mod/mod_log_config.html[Defined here] : "%a %l %u %t \"%r\" %>s %b %D"

Parse with https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns[Logstash] using `%{COMMONAPACHELOG} %{BASE10NUM:time_to_serve}`.


== How to run

=== Environment prerequisite

To produce the reports from the logs you need the following installed:

|===
|Technology | Version tested aginst

|Java
|openjdk version "1.8.0_60"

|Logstash
|1.5.4

|===


=== Create the report for stats per minute

The report is created using a couple of different tasks so these are pulled together with Gradle. You do not need to have
Gradle installed as it is being run using the wrapper.

Running the parser against the JSON version of the log data will produce a report to standard out with the metrics for each minute.

The report format is line delimited JSON.

The `jsonData` property can be supplied if you wish to override the value in `gradle.properties`.

    ./gradlew -q createAccessLogReport [-PapacheLog=test_data/20_200s_over_2_minutes.log]

To run the report on the provided data do this:

    ./gradlew getDataFile
    ./gradlew -q createAccessLogReport -PapacheLog=data/access.log

=== Testing

    ./gradlew test

== Decisions

=== Technology

Going with Logstash for the parsing as parsing Apache logs is a standard task
for Logstash and is tried and tested.

I would like to have done the stats gathering in Elastic Search but I could not
make that work in the available time.


== Plan

* Get the sample logs
* Write the requirements
* Decide technology for solution
* Create logstash conf to parse the logs
* Set up testing
* Get the numbers
* Done =========================================
* Add any missing documentation

=== Getting the numbers

To get the information from the data try these solutions in order:

* Logstash metrics plugin
** The default seems to be that this will give you rates based on when entries are added to the logs. I cannot find a way to use the timestamp in the log.
** I have found a way to set the Logstash timestamp to the timestamp value from the original log but the rates are per second.
** I looked through all the other filter plugins and could not find anything suitable.
* Elastic Search
** I tried this using aggregation but I could not work out how to get the values a per minute.
** I am going to give up and go with the scripting option.
* take the json output from logstash and do write a script

=== Testing

Take a small part of the log and manually count the up the values and use that
for testing.


== Issues

=== Missing minuts

I seem to be missing some minutes. This might be because some records have the
same time with a different offset but I need to take a closer loo.

        kevin at kevin-fedora in ~/projects/skyscanner/test-1-web-access-log-parsing/data on master [dirty]
        ± cut -f2 -d'[' access.log | cut -f1 -d']' | cut -f1-3 -d':' | sort -u | wc                                                                                           Sat 24 Oct 22:05:28 BST 2015 [untracked]
            367     367    6606

        kevin at kevin-fedora in ~/projects/skyscanner/test-1-web-access-log-parsing/data on master [dirty]
        ± cd ..                                                                                                                                                               Sat 24 Oct 22:05:35 BST 2015 [untracked]

        kevin at kevin-fedora in ~/projects/skyscanner/test-1-web-access-log-parsing on master [dirty]
        ± grep minute out7 | wc                                                                                                                                               Sat 24 Oct 22:05:39 BST 2015 [untracked]
            308     924   43132

I need to create a task that will verify the input minutes match the output minutes

=== Download

Add a onlyif to the file download that checks if a file of that name is there
so that it can be a dependency
